{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-17 10:16:42.344776: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-01-17 10:16:42.637089: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-17 10:16:43.992461: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1705454205.857811   31547 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1705454205.909375   31593 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 525.147.05), renderer: NVIDIA GeForce RTX 3090/PCIe/SSE2\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "감지시간: 1705454205.9147403\n",
      "이제 정자세로 돌아오세요.\n",
      "시간체크 스타트 1705454209.986203\n",
      "Preparation Pose Ready! 메시지가 표시되기를 기다리는 중입니다.\n",
      "이제 정자세로 돌아오세요.\n",
      "Preparation Pose Ready! 메시지가 표시되기를 기다리는 중입니다.\n",
      "이제 정자세로 돌아오세요.\n",
      "Preparation Pose Ready! 메시지가 표시되기를 기다리는 중입니다.\n",
      "이제 정자세로 돌아오세요.\n",
      "Preparation Pose Ready! 메시지가 표시되기를 기다리는 중입니다.\n",
      "이제 정자세로 돌아오세요.\n",
      "Preparation Pose Ready! 메시지가 표시되기를 기다리는 중입니다.\n",
      "이제 정자세로 돌아오세요.\n",
      "Preparation Pose Ready! 메시지가 표시되기를 기다리는 중입니다.\n",
      "이제 정자세로 돌아오세요.\n",
      "Preparation Pose Ready! 메시지가 표시되기를 기다리는 중입니다.\n",
      "이제 정자세로 돌아오세요.\n",
      "팔굽혀펴기 올라감! Count: 1\n",
      "이제 내려가세요.\n",
      "이제 정자세로 돌아오세요.\n",
      "팔굽혀펴기 올라감! Count: 2\n",
      "이제 내려가세요.\n",
      "이제 정자세로 돌아오세요.\n",
      "팔굽혀펴기 올라감! Count: 3\n",
      "이제 내려가세요.\n",
      "이제 정자세로 돌아오세요.\n",
      "팔굽혀펴기 올라감! Count: 4\n",
      "이제 내려가세요.\n",
      "이제 정자세로 돌아오세요.\n",
      "팔굽혀펴기 올라감! Count: 5\n",
      "이제 내려가세요.\n",
      "이제 정자세로 돌아오세요.\n",
      "팔굽혀펴기 올라감! Count: 6\n",
      "이제 내려가세요.\n",
      "이제 정자세로 돌아오세요.\n",
      "팔굽혀펴기 올라감! Count: 7\n",
      "이제 내려가세요.\n",
      "이제 정자세로 돌아오세요.\n",
      "팔굽혀펴기 올라감! Count: 8\n",
      "이제 내려가세요.\n",
      "이제 정자세로 돌아오세요.\n",
      "팔굽혀펴기 올라감! Count: 9\n",
      "이제 내려가세요.\n",
      "이제 정자세로 돌아오세요.\n",
      "팔굽혀펴기 올라감! Count: 10\n",
      "이제 내려가세요.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time  # Import the time module\n",
    "\n",
    "# MediaPipe Pose 모델 로드\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()\n",
    "\n",
    "# 카운터 초기화\n",
    "count = 0\n",
    "is_up = False  # 팔굽혀펴기가 올라가고 있는지 여부\n",
    "initial_detection = False  # 초기 검출 플래그\n",
    "start_displayed = False  # 시작 메시지 표시 여부\n",
    "count_initialized = False  # 초기화 플래그\n",
    "preparation_ready_time = None  # 시간 기록 변수\n",
    "\n",
    "# 이전 프레임에서 판단한 자세\n",
    "prev_pose = None\n",
    "\n",
    "# 이전에 일직선에 있던 시간\n",
    "straight_line_time = 0\n",
    "straight_line_duration = 2.0  # 2 seconds\n",
    "\n",
    "# 마지막 팔굽혀펴기 감지 시간\n",
    "last_pushup_time = time.time()\n",
    "print(\"감지시간:\",last_pushup_time)\n",
    "\n",
    "start_time = time.time()\n",
    "start_flag = False\n",
    "# 올바른 팔굽혀펴기 포즈를 판단하는 함수\n",
    "def is_correct_pushup_pose(keypoints):\n",
    "    global count, is_up, prev_pose, straight_line_time, preparation_ready_time, last_pushup_time\n",
    "\n",
    "    # 여기서는 예시로 왼쪽 어깨, 왼쪽 팔꿈치, 왼쪽 손목, 오른쪽 어깨, 오른쪽 팔꿈치, 오른쪽 손목을 활용합니다.\n",
    "    left_shoulder = keypoints[mp_pose.PoseLandmark.LEFT_SHOULDER.value]\n",
    "    left_elbow = keypoints[mp_pose.PoseLandmark.LEFT_ELBOW.value]\n",
    "    left_wrist = keypoints[mp_pose.PoseLandmark.LEFT_WRIST.value]\n",
    "    right_shoulder = keypoints[mp_pose.PoseLandmark.RIGHT_SHOULDER.value]\n",
    "    right_elbow = keypoints[mp_pose.PoseLandmark.RIGHT_ELBOW.value]\n",
    "    right_wrist = keypoints[mp_pose.PoseLandmark.RIGHT_WRIST.value]\n",
    "\n",
    "    # 팔굽혀펴기 시작자세 판단 (손목, 팔꿈치, 어깨가 일직선)\n",
    "    if (\n",
    "        left_shoulder.y < left_elbow.y < left_wrist.y\n",
    "        and right_shoulder.y < right_elbow.y < right_wrist.y\n",
    "    ): \n",
    "        global start_flag\n",
    "        if start_flag == False:\n",
    "            # 현재 시간을 가져오기\n",
    "            global start_time\n",
    "            start_time = time.time()\n",
    "            print(\"시간체크 스타트\", start_time)\n",
    "            start_flag = True\n",
    "\n",
    "        current_pose = \"up\"\n",
    "        straight_line_time = time.time() if straight_line_time == 0 else straight_line_time\n",
    "        last_pushup_time = time.time()  # 감지된 팔굽혀펴기 시간 업데이트\n",
    "    else:\n",
    "        current_pose = \"down\"\n",
    "        straight_line_time = 0\n",
    "\n",
    "    # 판단한 자세가 이전과 다를 때 count 증가\n",
    "    if current_pose != prev_pose:\n",
    "        if current_pose == \"up\":\n",
    "            # Check if Preparation Pose Ready message was displayed\n",
    "            if preparation_ready_time is not None:\n",
    "                count += 1\n",
    "                if time.time() - last_pushup_time >= 2.0 and not is_up:\n",
    "                   print(\"이떄 end표시:\",time.time()-last_pushup_time)\n",
    "                   cv2.putText(frame, \"End!\", (10, 180), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "                is_up = True\n",
    "                print(\"팔굽혀펴기 올라감! Count:\", count)\n",
    "                print(\"이제 내려가세요.\")\n",
    "            else:\n",
    "                print(\"Preparation Pose Ready! 메시지가 표시되기를 기다리는 중입니다.\")\n",
    "        else:\n",
    "            is_up = False\n",
    "            print(\"이제 정자세로 돌아오세요.\")\n",
    "\n",
    "    # 팔굽혀펴기 준비자세 판단\n",
    "    if straight_line_time > 0 and time.time() - straight_line_time >= straight_line_duration:\n",
    "        if preparation_ready_time is None:  # Set the preparation_ready_time only once\n",
    "            cv2.putText(frame, \"Preparation Pose Ready!\", (10, 150), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "            preparation_ready_time = time.time()  # 기록해둠\n",
    "            time.sleep(3)\n",
    "\n",
    "    prev_pose = current_pose\n",
    "\n",
    "    return True if current_pose == \"up\" else False\n",
    "\n",
    "# 동영상 파일 경로\n",
    "video_path = '/home/alpaco/Hometraining/qqq.mp4'\n",
    "\n",
    "# 웹캠으로부터 비디오 스트림 읽기\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# 비디오 프레임 크기 조정\n",
    "target_width, target_height = 1024, 768\n",
    "\n",
    "while cap.isOpened():\n",
    "\n",
    "    # 초기 검출 플래그 초기화\n",
    "    \n",
    "    # 프레임 읽기\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.resize(frame, (target_width, target_height))\n",
    "\n",
    "    # Mediapipe Pose 적용\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = pose.process(frame_rgb)\n",
    "\n",
    "    # 감지된 포즈 점 찾기\n",
    "    if results.pose_landmarks:\n",
    "        landmarks = results.pose_landmarks.landmark\n",
    "        # 여기에서 is_correct_pushup_pose 함수를 사용하여 올바른 팔굽혀펴기 포즈인지 확인\n",
    "        is_correct_pushup_pose(landmarks)\n",
    "\n",
    "    # 초기화면에서 count 초기화\n",
    "    if not count_initialized and preparation_ready_time is not None:\n",
    "        count = 0\n",
    "        count_initialized = True\n",
    "\n",
    "    global start_time\n",
    "    if time.time() > start_time + 60:\n",
    "        print(\"1분 종료\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1089.65"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 기초 대사량 (BMR) 계산 미플린 공식\n",
    "gender = \"남자\"\n",
    "height = 173 \n",
    "weight = 65\n",
    "age = 30\n",
    "# 기초대사량에서 500~1000사이 얼마나 줄여서 섭취할지 사용자 입력 받아야함\n",
    "diet_kcal = 500\n",
    "\n",
    "if gender == \"남자\":\n",
    "    #남자\n",
    "    base_kcal = (10*weight) + (6.25 * height) - (5*age) + 5\n",
    "else:\n",
    "    #여자\n",
    "    base_kcal = (10*weight) + (6.25 * height) - (5*age) + 16.1\n",
    "\n",
    "#팔굽혀펴기 kg당 kcal 소모 계산\n",
    "\n",
    "if weight // 10 * 10 == 50:\n",
    "    palgub_kal = count / 100 * 28\n",
    "elif weight // 10 * 10 == 60:\n",
    "    palgub_kal = count / 100 * 34\n",
    "elif weight // 10 * 10 == 70:\n",
    "    palgub_kal = count / 100 * 41\n",
    "elif weight // 10 * 10 == 80:\n",
    "    palgub_kal = count / 100 * 49\n",
    "elif weight // 10 * 10 == 90:\n",
    "    palgub_kal = count / 100 * 59\n",
    "\n",
    "# 총 에너지 소비량= 기초대사량 + 운동으로 소모된 칼로리\n",
    "\n",
    "total_kcal = base_kcal + palgub_kal\n",
    "\n",
    "final_kal = total_kcal-diet_kcal\n",
    "final_kal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 224x256 1 Squid, 1 lettuce, 1 sausage, 1 shrimp, 1 onion, 149.7ms\n",
      "Speed: 7.2ms preprocess, 149.7ms inference, 15.4ms postprocess per image at shape (1, 3, 224, 256)\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "import torch\n",
    "\n",
    "# Load a model\n",
    "\n",
    "model = YOLO('/home/alpaco/Hometraining/train34/weights/best.pt')  # load a pretrained model (recommended for training)\n",
    "\n",
    "# Run batched inference on a list of images\n",
    "results = model(['/home/alpaco/Hometraining/train34/final.jpg'])  # return a list of Results objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_names = list(results[0].names.values())\n",
    "detection_ingre = set([result_names[int(i)] for i in results[0].boxes.cls]) \n",
    "classes=' '.join(detection_ingre)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai==0.28\n",
      "  Downloading openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: requests>=2.20 in /home/alpaco/anaconda3/envs/test/lib/python3.8/site-packages (from openai==0.28) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /home/alpaco/anaconda3/envs/test/lib/python3.8/site-packages (from openai==0.28) (4.66.1)\n",
      "Collecting aiohttp (from openai==0.28)\n",
      "  Downloading aiohttp-3.9.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/alpaco/anaconda3/envs/test/lib/python3.8/site-packages (from requests>=2.20->openai==0.28) (3.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/alpaco/anaconda3/envs/test/lib/python3.8/site-packages (from requests>=2.20->openai==0.28) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/alpaco/anaconda3/envs/test/lib/python3.8/site-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/alpaco/anaconda3/envs/test/lib/python3.8/site-packages (from requests>=2.20->openai==0.28) (2023.7.22)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/alpaco/anaconda3/envs/test/lib/python3.8/site-packages (from aiohttp->openai==0.28) (23.1.0)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->openai==0.28)\n",
      "  Downloading multidict-6.0.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (121 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.3/121.3 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting yarl<2.0,>=1.0 (from aiohttp->openai==0.28)\n",
      "  Downloading yarl-1.9.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->openai==0.28)\n",
      "  Downloading frozenlist-1.4.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->openai==0.28)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting async-timeout<5.0,>=4.0 (from aiohttp->openai==0.28)\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.9.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading frozenlist-1.4.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (240 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.9/240.9 kB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading yarl-1.9.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (308 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m308.8/308.8 kB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n",
      "Successfully installed aiohttp-3.9.1 aiosignal-1.3.1 async-timeout-4.0.3 frozenlist-1.4.1 multidict-6.0.4 openai-0.28.0 yarl-1.9.4\n"
     ]
    }
   ],
   "source": [
    "!pip install openai==0.28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'해당 레시피의 칼로리와 레시피를 알려드리겠습니다. \\n\\n레시피: Sausage Onion Lettuce Squid Shrimp 샌드위치\\n\\n재료:\\n- 소시지: 1개\\n- 양파: 1/4개\\n- 상추: 약간\\n- 오징어: 2마리\\n- 새우: 6마리\\n- 빵: 2조각\\n\\n칼로리:\\n- 소시지: 150칼로리\\n- 양파: 16칼로리\\n- 상추: 5칼로리\\n- 오징어: 80칼로리\\n- 새우: 100칼로리\\n- 빵: 738.65칼로리 (2조각)\\n\\n총 칼로리: 1089.65칼로리\\n\\n레시피:\\n1. 소시지를 팬에 볶아 익히고, 양파를 채 썰어 함께 볶아줍니다.\\n2. 오징어와 새우를 소금과 후추로 조미하여 팬에 볶아줍니다.\\n3. 빵을 굽거나 토스터기에 구워서 준비합니다.\\n4. 빵 한 조각 위에 상추를 올리고, 그 위에 소시지와 양파를 올려줍니다.\\n5. 그 위에 오징어와 새우를 올리고, 다른 빵 조각으로 덮어줍니다.\\n6. 샌드위치를 잘라서 서빙합니다.\\n\\n이렇게 준비하면 총 1089.65칼로리의 Sausage Onion Lettuce Squid Shrimp 샌드위치를 즐길 수 있습니다.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "# open ai에서 발급받은 api key를 등록합니다\n",
    "OPENAI_YOUR_KEY = \"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\"\n",
    "openai.api_key = OPENAI_YOUR_KEY\n",
    "\n",
    "# 사용 모델을 설정합니다. chat GPT는 gpt-3.5-turbo를 사용합니다.\n",
    "MODEL = \"gpt-3.5-turbo\"\n",
    "USER_INPUT_MSG = (\"나는 {}가 있고 {}칼로리 내의 레시피를 알려줘, 이때 음식의 칼로리랑 레시피를 알려줘.\").format(classes,final_kal)\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a heath mento.\"},\n",
    "        {\"role\": \"user\", \"content\": USER_INPUT_MSG},\n",
    "        #{\"role\": \"assistant\", \"content\": \"Who's there?\"},\n",
    "    ],\n",
    "    temperature=0,\n",
    ")\n",
    "#system : 시스템의 어떤 역할을 부여합니다. 가령 아래와 같이 chatbot에게 helpful assitant 라는 역할을 부여할 수 있습니다.\n",
    "#user : 실제 prompt에 입력하는 메시지 역할을 합니다.\n",
    "#assistant : 반복적으로 질문을 할 경우, 이전 결과의 맥락을 유지하기 위해 이전 응답을 반영할 수 있습니다.\n",
    "\n",
    "response['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "냉장고에 당근, 오징어, 배추, 새우, 양파가 있는데 1087.95kcal 내로 하루 식단을 짜줘\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yoloV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
